{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import random, math, torch\nimport torch.nn.functional as F\nimport torchvision.transforms as T\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch.nn as nn\nimport torchvision\nimport datetime\nfrom sklearn.metrics import f1_score, classification_report\n\nclass Config:\n    def __init__(self, dictionary):\n        for key, value in dictionary.items():\n            if isinstance(value, dict):\n                setattr(self, key, Config(value))\n            else:\n                setattr(self, key, value)\n\n    def to_dict(self):\n        dictionary = {}\n        # import pdb; pdb.set_trace()\n        for key, value in self.__dict__.items():\n            if isinstance(value, Config):\n                dictionary[key] = value.to_dict()\n            else:\n                dictionary[key] = value\n        \n        return dictionary\n                \ndef log_classifier_metrics(model, metrics, epoch, mode, writer):\n    \"\"\"Log and print training/validation metrics.\"\"\"\n     \n    metrics_dict = {\n        'loss/all': metrics[0].mean().item(),\n        'loss/pos': metrics[0, metrics[2] == 1].mean().item(),\n        'loss/neg': metrics[0, metrics[2] == 0].mean().item()\n    }\n    \n    pos_mask = metrics[2] == 1\n    neg_mask = ~pos_mask\n    \n    true_pos = (metrics[1, pos_mask] > 0.5).sum()\n    true_neg = (metrics[1, neg_mask] <= 0.5).sum()\n    false_pos = (metrics[1, neg_mask] > 0.5).sum()\n    false_neg = (metrics[1, pos_mask] <= 0.5).sum()\n\n    recall = true_pos / (true_pos + false_neg)\n    precision = true_pos / (true_pos + false_pos)\n    f1_score = (1+1**2) * (precision * recall) / (1**2*precision + recall)\n    f_5_score = (1+.5**2) * (precision * recall) / (.5**2*precision + recall)\n    f2_score = (1+2**2) * (precision * recall) / (2**2*precision + recall)\n    \n    metrics_dict.update({\n        'metric/recall': 100 * recall,\n        'metric/precision': 100 * precision,\n        'metric/f1_score': 100 * f1_score,\n        'metric/f_5_score': 100 * f_5_score,\n        'metric/f2_score': 100 * f2_score,\n        'metric/accuracy': 100 * (true_pos + true_neg) / (true_pos + true_neg + false_pos + false_neg),\n        'metric/accuracy_pos': 100 * true_pos / (true_pos + false_neg),\n        'metric/accuracy_neg': 100 * true_neg / (true_neg + false_pos)\n    })\n\n    for k,v in metrics_dict.items():\n        writer.add_scalar(mode.lower()+'/'+k, v, epoch)\n        \n    if mode == 'Train':\n        for name, param in model.named_parameters():\n            writer.add_histogram(f\"{name}_weights\", param, epoch)\n            writer.add_histogram(f\"{name}_grad\", param.grad, epoch)\n    \n    log_format = (\n        f\"Epoch {epoch}, {datetime.datetime.now().strftime('%Y-%m-%d, %H:%M:%S')}: \"\n        f\"{mode} Loss {metrics_dict['loss/all']:.2f}, \"\n        f\"{mode} Loss/Pos {metrics_dict['loss/pos']:.2f}, \"\n        f\"{mode} Loss/Neg {metrics_dict['loss/neg']:.2f}, \"\n        f\"\\n{mode} Metric/Recall {metrics_dict['metric/recall']:.2f}%, \"\n        f\"{mode} Metric/Precision {metrics_dict['metric/precision']:.2f}%, \"\n        f\"{mode} Metric/F1 Score {metrics_dict['metric/f1_score']:.2f}%, \"\n        f\"{mode} Metric/F.5 Score {metrics_dict['metric/f_5_score']:.2f}%, \"\n        f\"{mode} Metric/F2 Score {metrics_dict['metric/f2_score']:.2f}%, \"\n        f\"{mode} Metric/Accuracy {metrics_dict['metric/accuracy']:.2f}%, \"\n        f\"{mode} Metric/Accuracy_pos {metrics_dict['metric/accuracy_pos']:.2f}%, \"\n        f\"{mode} Metric/Accuracy_neg {metrics_dict['metric/accuracy_neg']:.2f}%\"\n    )\n    print(log_format)\n    print('-' * 50)\n\n    return metrics_dict\n\ndef log_segmenter_metrics(model, metrics, epoch, mode, writer):\n    \"\"\"Log and print training/validation metrics.\"\"\"\n     \n    metrics_dict = {\n        'loss/all': metrics[0].mean().item(),\n    }\n    \n    true_pos = metrics[1].sum()\n    true_neg = metrics[2].sum()\n    false_pos = metrics[3].sum()\n    false_neg = metrics[4].sum()\n\n    recall = true_pos / (true_pos + false_neg)\n    precision = true_pos / (true_pos + false_pos)\n    f1_score = (1+1**2) * (precision * recall) / (1**2*precision + recall)\n    f_5_score = (1+.5**2) * (precision * recall) / (.5**2*precision + recall)\n    f2_score = (1+2**2) * (precision * recall) / (2**2*precision + recall)\n    \n    metrics_dict.update({\n        'metric/recall': 100 * recall,\n        'metric/precision': 100 * precision,\n        'metric/f1_score': 100 * f1_score,\n        'metric/f_5_score': 100 * f_5_score,\n        'metric/f2_score': 100 * f2_score,\n        'metric/accuracy': 100 * (true_pos + true_neg) / (true_pos + true_neg + false_pos + false_neg),\n        'metric/accuracy_pos': 100 * true_pos / (true_pos + false_neg),\n        'metric/accuracy_neg': 100 * true_neg / (true_neg + false_pos)\n    })\n\n    for k,v in metrics_dict.items():\n        writer.add_scalar(mode.lower()+'/'+k, v, epoch)\n    \n    log_format = (\n        f\"Epoch {epoch}, {datetime.datetime.now().strftime('%Y-%m-%d, %H:%M:%S')}: \"\n        f\"{mode} Loss {metrics_dict['loss/all']:.2f}, \"\n        f\"\\n{mode} Metric/Recall {metrics_dict['metric/recall']:.2f}%, \"\n        f\"{mode} Metric/Precision {metrics_dict['metric/precision']:.2f}%, \"\n        f\"{mode} Metric/F1 Score {metrics_dict['metric/f1_score']:.2f}%, \"\n        f\"{mode} Metric/F.5 Score {metrics_dict['metric/f_5_score']:.2f}%, \"\n        f\"{mode} Metric/F2 Score {metrics_dict['metric/f2_score']:.2f}%, \"\n        f\"{mode} Metric/Accuracy {metrics_dict['metric/accuracy']:.2f}%, \"\n        f\"{mode} Metric/Accuracy_pos {metrics_dict['metric/accuracy_pos']:.2f}%, \"\n        f\"{mode} Metric/Accuracy_neg {metrics_dict['metric/accuracy_neg']:.2f}%\"\n    )\n    print(log_format)\n    print('-' * 50)\n\n    return metrics_dict\n\ndef show_nodule(sample, label, irc_center, cmap='gray', figsize=(10, 4)):\n    \"\"\"\n    Visualize nodule slices from different perspectives\n    \n    Args:\n        sample (np.ndarray): Volume data\n        irc_center (Tuple[int, int,int]): Center coordinates\n        label (int): Nodule classification\n        cmap (str): Colormap for visualization\n        figsize (Tuple[int, int]): Figure size\n    \"\"\"\n    sample = sample.squeeze(0)\n    irc_center = irc_center.squeeze()    \n    wi, wr, wc = np.array(sample.shape) // 2\n    i, r, c = irc_center\n    titles = [f'Index {i}', f'Row {r}', f'Column {c}']\n    nod = 'Nodule' if label else 'Not Nodule'\n\n    # Normalize and extract slices\n    def normalize(arr):\n        return (arr - arr.min()) / (arr.max() - arr.min() + 1e-8)\n\n    index = normalize(np.transpose(sample, (2,1,0))[:,:,wi])\n    col = normalize(sample[:,:,wc])\n    row = normalize(np.transpose(sample, (0,2,1))[:,:,wr])\n\n    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=figsize)\n    \n    ax1.imshow(index, cmap=cmap)\n    ax1.set_title(titles[0])\n\n    ax2.imshow(row, cmap=cmap)\n    ax2.set_title(titles[1])\n    \n    ax3.imshow(col, cmap=cmap)\n    ax3.set_title(titles[2])\n\n    fig.suptitle(nod)\n    plt.tight_layout()\n    plt.show()\n    \ndef augment_candidates_3d(candidates, label, augment):\n    # TODO I NEED TO TRANFORM FOR MANY CANDIDATES\n    transform_t = torch.eye(4).to(candidates.device)\n\n    for i in range(3):\n        if hasattr(augment, 'flip') and augment.flip:\n            if random.random() > 0.5:\n                transform_t[i,i] *= -1\n\n        if hasattr(augment, 'offset'):\n            offset_float = augment.offset\n            random_float = (random.random() * 2 - 1)\n            transform_t[i,3] = offset_float * random_float\n\n        if hasattr(augment, 'scale'):\n            scale_float = augment.scale\n            random_float = (random.random() * 2 - 1)\n            transform_t[i,i] *= 1.0 + scale_float * random_float\n\n\n    if hasattr(augment, 'rotate') and augment.rotate:\n        angle_rad = random.random() * math.pi * 2\n        s = math.sin(angle_rad)\n        c = math.cos(angle_rad)\n\n        rotation_t = torch.tensor([\n            [c, -s, 0, 0],\n            [s, c, 0, 0],\n            [0, 0, 1, 0],\n            [0, 0, 0, 1],\n        ]).to(candidates.device)\n\n        transform_t @= rotation_t\n\n    affine_t = F.affine_grid(\n            transform_t[:3].to(torch.float32).expand(candidates.shape[0], -1, -1),\n            candidates.size(),\n            align_corners=False,\n        )\n\n    augmented_chunk = F.grid_sample(\n            candidates,\n            affine_t,\n            padding_mode='border',\n            align_corners=False,\n        )\n\n    if hasattr(augment, 'noise'):\n        noise_t = torch.randn_like(augmented_chunk).to(candidates.device)\n        noise_t *= augment.noise\n\n        augmented_chunk += noise_t\n\n    if hasattr(augment, 'mixup'):\n        alpha = augment.mixup\n        lambda_ = torch.distributions.Beta(alpha, alpha).sample().item()\n\n        batch_size = candidates[label == 1].size(0)\n        index = torch.randperm(batch_size).to(candidates.device)\n\n        augmented_chunk[label == 1] = lambda_ * augmented_chunk[label == 1] + \\\n                (1 - lambda_) * augmented_chunk[label == 1][index]\n   \n    return augmented_chunk, label\n\ndef augment_candidates_2d(candidates, label, augment):\n    \"\"\"\n    Augment 2D image candidates using torchvision transforms.\n    \n    Args:\n        candidates: Tensor of shape (batch_size, channels, height, width)\n        label: Binary tensor indicating positive/negative samples\n        augment: Object containing augmentation parameters\n    \n    Returns:\n        tuple: (augmented_candidates, label)\n    \"\"\"\n    batch_size = candidates.shape[0]\n    device = candidates.device\n    \n    # Initialize identity transform matrix\n    transform_t = torch.eye(3).to(device)\n    \n    # Handle flipping\n    if hasattr(augment, 'flip') and augment.flip:\n        if random.random() > 0.5:\n            candidates = T.functional.hflip(candidates)\n            label = T.functional.hflip(label)\n        if random.random() > 0.5:\n            candidates = T.functional.vflip(candidates)\n            label = T.functional.vflip(label)\n\n    # Handle scaling\n    if hasattr(augment, 'scale'):\n        scale_factor = 1.0 + augment.scale * (random.random() * 2 - 1)\n        transform_t[0, 0] *= scale_factor\n        transform_t[1, 1] *= scale_factor\n    \n    # Handle rotation\n    if hasattr(augment, 'rotate') and augment.rotate:\n        angle_rad = random.random() * math.pi * 2\n        angle_deg = math.degrees(angle_rad)\n        rotation_matrix = torch.tensor([\n            [math.cos(angle_rad), -math.sin(angle_rad), 0],\n            [math.sin(angle_rad), math.cos(angle_rad), 0],\n            [0, 0, 1]\n        ]).to(device)\n        transform_t = transform_t @ rotation_matrix\n    \n    # Handle translation/offset\n    if hasattr(augment, 'offset'):\n        offset_x = augment.offset * (random.random() * 2 - 1)\n        offset_y = augment.offset * (random.random() * 2 - 1)\n        transform_t[0, 2] = offset_x\n        transform_t[1, 2] = offset_y\n    \n    # Convert 3x3 transformation matrix to 2x3 affine matrix expected by F.affine_grid\n    affine_matrix = transform_t[:2].unsqueeze(0).repeat(batch_size, 1, 1)\n    \n    # Apply affine transformation\n    grid = F.affine_grid(\n        affine_matrix,\n        candidates.size(),\n        align_corners=False\n    )\n    \n    augmented_chunk = F.grid_sample(\n        candidates,\n        grid,\n        padding_mode='border',\n        align_corners=False\n    )\n\n    label = F.grid_sample(\n        label,\n        grid,\n        padding_mode='border',\n        align_corners=False\n    )\n    \n    # Add noise if specified\n    if hasattr(augment, 'noise'):\n        if random.random() > 0.5:\n            noise = torch.randn_like(augmented_chunk).to(device) * augment.noise\n            augmented_chunk += noise\n    \n    return augmented_chunk, label\n\nclass FeatureMapLogger(nn.Module):\n    def __init__(self, model, writer, visualize):\n        super().__init__()\n        self.model = model\n        self.writer = writer\n        self.visualize = visualize\n        self.hooks = []\n        self.feature_maps = {}\n        \n        # Register hooks for each layer we want to visualize\n        for name, layer in model.named_modules():\n            if isinstance(layer, nn.Conv3d):\n                self.hooks.append(\n                    layer.register_forward_hook(\n                        self.named_hook(name)\n                    )\n                )\n\n    def named_hook(self, name): \n        def fun_hook(_, __, output):\n            self._hook_fn(name, output)\n        return fun_hook\n    \n    def _hook_fn(self, layer_name, output):\n        # Store the feature maps\n        self.feature_maps[layer_name] = output\n    \n    def forward(self, x, step=0):\n        # Forward pass through the model\n        self.model(x)\n        \n        # Log feature maps to TensorBoard\n        if self.visualize:\n            i = 0\n            col = 2\n            row = len(self.feature_maps) // col\n            fig, axs = plt.subplots(row, col, figsize=(10,10))\n            axs = axs.flatten()\n\n        for name, feature_map in self.feature_maps.items():\n            # Get first volumetric image in batch\n            depth_middle = feature_map.shape[-3] // 2\n            feature_map = feature_map[0,:,depth_middle]\n\n            # Create grid of feature maps\n            grid = torchvision.utils.make_grid(\n                feature_map.unsqueeze(1),\n                normalize=True,\n                nrow=8,\n                padding=0\n            )\n            \n            # Log to TensorBoard\n            self.writer.add_image(\n                f'Feature Maps/{name}/{step}',\n                grid,\n                step\n            )\n            \n            if self.visualize:\n                grid_np = grid.cpu().numpy().transpose(1, 2, 0)\n                axs[i].imshow(grid_np)\n                axs[i].set_title(f'{name}')\n                axs[i].set_axis_off()\n                i+=1\n\n        if self.visualize:\n            fig.suptitle('Feature Maps: Middle Slice of The Depth')\n            plt.tight_layout()\n            plt.show()\n    \n        return x\n\n    def close(self):\n        for hook in self.hooks:\n            hook.remove()\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib\nfrom mpl_toolkits.mplot3d import Axes3D\n\ndef create_3d_tomograph(data, slice_spacing=1, colormap='viridis', \n                       transparency=0.15, threshold=0.3):\n    \"\"\"\n    Create a 3D visualization of tomographic data with controllable transparency.\n    \n    Parameters:\n    data: 3D numpy array of tomographic data\n    slice_spacing: spacing between slices in the visualization\n    colormap: matplotlib colormap to use for the visualization\n    transparency: base transparency level (0 = fully transparent, 1 = solid)\n    threshold: minimum intensity value to display (0-1, filters out noise)\n    \"\"\"\n    \n    if len(data.shape) > 3:\n        data = data.squeeze()\n\n    data = data.permute(1,2,0).numpy()\n    \n    # Normalize data to 0-1 range\n    data_normalized = (data - np.min(data)) / (np.max(data) - np.min(data))\n\n    # Get dimensions of the data\n    x_dim, y_dim, z_dim = data.shape\n    \n    # Create coordinate matrices\n    x, y = np.meshgrid(np.arange(x_dim), np.arange(y_dim))\n    \n    # Create the 3D figure\n    fig = plt.figure(figsize=(12, 8))\n    ax = fig.add_subplot(111, projection='3d')\n    \n    # Plot each slice with adaptive transparency\n    for i in range(z_dim):\n        # Get the 2D slice\n        slice_data = data_normalized[:, :, i]\n        \n        # Create mask for thresholding\n        mask = slice_data > threshold\n        \n        # Create color array with transparency\n        colors = matplotlib.colormaps[colormap](slice_data)\n        \n        # Adjust alpha channel based on intensity and mask\n        colors[:, :, 3] = np.where(mask, \n                                  slice_data * transparency, \n                                  0)  # Make low-intensity voxels fully transparent\n        \n        # Create the surface plot for this slice\n        surf = ax.plot_surface(x, y, i * np.ones_like(x),\n                             facecolors=colors,\n                             rstride=1, cstride=1)\n    \n    # Customize the visualization\n    ax.set_xlabel('X axis')\n    ax.set_ylabel('Y axis')\n    ax.set_zlabel('Z axis (Slices)')\n    ax.set_title('3D Tomograph Visualization')\n        \n    # Set the viewing angle to better see internal structures\n    ax.view_init(elev=20, azim=45)\n    \n    plt.show()\n\ndef log_masked_image(data, model, writer, epoch, visualize):    \n    def create_masked_image(image, mask, alpha=1, mask_color='red'):\n        color_rgb = plt.cm.colors.to_rgb(mask_color)\n        rgb_image = np.stack([image] * 3, axis=-1)\n        colored_mask = np.zeros_like(rgb_image)\n        for i in range(3):\n            colored_mask[..., i] = mask * color_rgb[i]\n        \n        blended = rgb_image.copy() \n        mask_3d = np.stack([mask] * 3, axis=-1)\n        blended[mask_3d] = (1 - alpha) * rgb_image[mask_3d] + alpha * colored_mask[mask_3d]\n        blended = np.clip(blended, 0, 1)\n        return blended\n\n    # import pdb; pdb.set_trace()\n    mask_p = (model(data[0][0:1])[0] > 0.5).squeeze().cpu()\n    mask_gt = (data[1][0] > 0.5).squeeze().cpu()\n    image = data[0][0,1].cpu()\n    image_gt = create_masked_image(image, mask_gt, mask_color='red')\n    image_p = create_masked_image(image, mask_p, mask_color='yellow')\n\n    # import pdb; pdb.set_trace()\n    combined = np.concatenate([image_gt, image_p], axis=0)\n    writer.add_image(f'Masked Images/{epoch}', combined.transpose(2, 1, 0), epoch)\n    # writer.add_image(f'Predicted Mask/{epoch}/2', image_p.transpose(2, 1, 0), epoch)\n\n    if visualize:\n        fig, axs = plt.subplots(1, 2)\n        axs = axs.flatten()\n        axs[0].imshow(image_gt, cmap='gray')\n        axs[0].set_title(f'Ground Truth MAsk')\n        axs[0].set_axis_off()\n\n        axs[1].imshow(image_p, cmap='gray')\n        axs[1].set_title(f'Predicted Mask')\n        axs[1].set_axis_off()\n\n        plt.tight_layout()\n        plt.show()\n\n    y_pred = mask_p.flatten()\n    y_true = mask_gt.flatten()\n    f1_macro = f1_score(y_true, y_pred, average='macro')\n    print(f'F1 Macro: {f1_macro:.2f}')\n    print(classification_report(y_true, y_pred))\n    return f1_macro\n\nclass F1MacroLoss(nn.Module):\n    def __init__(self, epsilon=1e-7):\n        super().__init__()\n        self.epsilon = epsilon\n        \n    def forward(self, y_pred, y_true):\n        \"\"\"\n        Calculate differentiable F1 macro loss.\n        \n        Args:\n            y_pred: Predicted probabilities of shape (batch_size, num_classes)\n            y_true: One-hot encoded target of shape (batch_size, num_classes)\n        \n        Returns:\n            f1_macro_loss: The calculated loss\n        \"\"\"\n        # Assert tensors are of the same shape\n        assert y_pred.shape == y_true.shape, \"Predictions and targets must have the same shape\"\n        \n        # Convert probabilities to binary predictions (0 or 1)\n        y_pred = torch.sigmoid(y_pred) if y_pred.shape[1] == 1 else torch.softmax(y_pred, dim=1)\n        \n        # Calculate true positives, false positives, and false negatives per class\n        tp = torch.sum(y_true * y_pred, dim=0)\n        fp = torch.sum((1 - y_true) * y_pred, dim=0)\n        fn = torch.sum(y_true * (1 - y_pred), dim=0)\n        \n        # Calculate precision and recall per class\n        precision = tp / (tp + fp + self.epsilon)\n        recall = tp / (tp + fn + self.epsilon)\n        \n        # Calculate F1 score per class\n        f1_per_class = 2 * (precision * recall) / (precision + recall + self.epsilon)\n        \n        # Calculate macro average\n        f1_macro = torch.mean(f1_per_class)\n        \n        # Return loss (1 - F1 score)\n        return 1 - f1_macro\n\n    def __repr__(self):\n        return f\"F1MacroLoss(epsilon={self.epsilon})\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}